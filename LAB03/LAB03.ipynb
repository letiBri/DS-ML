{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b9c870-abf6-4a34-9cfd-5c456f0316d5",
   "metadata": {},
   "source": [
    "# LAB 03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6aeff4-83b4-4ca8-97f7-179b247d0d93",
   "metadata": {},
   "source": [
    "# KNN design and implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fce01-fd85-47eb-92ee-d25c4500b58c",
   "metadata": {},
   "source": [
    "**es1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ab0c79-e107-4720-ae06-12fcb4e4af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv (\"iris.csv\", header = None)\n",
    "# header=None parameter -- meaning that Pandas will expect to find a valid data point in the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c617cf7e-d98f-441c-9203-cce98626d15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
       "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d0e69-992c-4828-8c6c-519e5d384775",
   "metadata": {},
   "source": [
    "**es2,es3**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d0bb558-3643-47b7-bf20-eea8afc89575",
   "metadata": {},
   "source": [
    "Before building our matrices X_train, X_test and vectors y_train, y_test, we will first build the design matrix X and the labels to be predicted y.\n",
    "\n",
    "A design matrix is a canonical way of representing a dataset: each row of the design matrix contains a data point, each column represents one of the features of our data points.\n",
    "\n",
    "For the iris dataset, the design matrix will have 150 rows (one for each iris measured) and 4 columns (one for each measurement -- petal width and length, sepal width and length). The labels vector will instead be a row of values: the i-th value will be the target label for the i-th element of our design matrix.\n",
    "\n",
    "We can access the matrix representation underneath the DataFrame df using the values attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6cad8f4-c99b-4dcb-86dc-c053b3f1b901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.9, 3.0, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.7, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [4.6, 3.1, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.6, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [5.4, 3.9, 1.7, 0.4, 'Iris-setosa'],\n",
       "       [4.6, 3.4, 1.4, 0.3, 'Iris-setosa'],\n",
       "       [5.0, 3.4, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [4.4, 2.9, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [5.4, 3.7, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [4.8, 3.4, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [4.8, 3.0, 1.4, 0.1, 'Iris-setosa'],\n",
       "       [4.3, 3.0, 1.1, 0.1, 'Iris-setosa'],\n",
       "       [5.8, 4.0, 1.2, 0.2, 'Iris-setosa'],\n",
       "       [5.7, 4.4, 1.5, 0.4, 'Iris-setosa'],\n",
       "       [5.4, 3.9, 1.3, 0.4, 'Iris-setosa'],\n",
       "       [5.1, 3.5, 1.4, 0.3, 'Iris-setosa'],\n",
       "       [5.7, 3.8, 1.7, 0.3, 'Iris-setosa'],\n",
       "       [5.1, 3.8, 1.5, 0.3, 'Iris-setosa'],\n",
       "       [5.4, 3.4, 1.7, 0.2, 'Iris-setosa'],\n",
       "       [5.1, 3.7, 1.5, 0.4, 'Iris-setosa'],\n",
       "       [4.6, 3.6, 1.0, 0.2, 'Iris-setosa'],\n",
       "       [5.1, 3.3, 1.7, 0.5, 'Iris-setosa'],\n",
       "       [4.8, 3.4, 1.9, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.0, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.4, 1.6, 0.4, 'Iris-setosa'],\n",
       "       [5.2, 3.5, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5.2, 3.4, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.7, 3.2, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [4.8, 3.1, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [5.4, 3.4, 1.5, 0.4, 'Iris-setosa'],\n",
       "       [5.2, 4.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [5.5, 4.2, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [5.0, 3.2, 1.2, 0.2, 'Iris-setosa'],\n",
       "       [5.5, 3.5, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [4.4, 3.0, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [5.1, 3.4, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.5, 1.3, 0.3, 'Iris-setosa'],\n",
       "       [4.5, 2.3, 1.3, 0.3, 'Iris-setosa'],\n",
       "       [4.4, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.5, 1.6, 0.6, 'Iris-setosa'],\n",
       "       [5.1, 3.8, 1.9, 0.4, 'Iris-setosa'],\n",
       "       [4.8, 3.0, 1.4, 0.3, 'Iris-setosa'],\n",
       "       [5.1, 3.8, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [4.6, 3.2, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [5.3, 3.7, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.3, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [7.0, 3.2, 4.7, 1.4, 'Iris-versicolor'],\n",
       "       [6.4, 3.2, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [6.9, 3.1, 4.9, 1.5, 'Iris-versicolor'],\n",
       "       [5.5, 2.3, 4.0, 1.3, 'Iris-versicolor'],\n",
       "       [6.5, 2.8, 4.6, 1.5, 'Iris-versicolor'],\n",
       "       [5.7, 2.8, 4.5, 1.3, 'Iris-versicolor'],\n",
       "       [6.3, 3.3, 4.7, 1.6, 'Iris-versicolor'],\n",
       "       [4.9, 2.4, 3.3, 1.0, 'Iris-versicolor'],\n",
       "       [6.6, 2.9, 4.6, 1.3, 'Iris-versicolor'],\n",
       "       [5.2, 2.7, 3.9, 1.4, 'Iris-versicolor'],\n",
       "       [5.0, 2.0, 3.5, 1.0, 'Iris-versicolor'],\n",
       "       [5.9, 3.0, 4.2, 1.5, 'Iris-versicolor'],\n",
       "       [6.0, 2.2, 4.0, 1.0, 'Iris-versicolor'],\n",
       "       [6.1, 2.9, 4.7, 1.4, 'Iris-versicolor'],\n",
       "       [5.6, 2.9, 3.6, 1.3, 'Iris-versicolor'],\n",
       "       [6.7, 3.1, 4.4, 1.4, 'Iris-versicolor'],\n",
       "       [5.6, 3.0, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [5.8, 2.7, 4.1, 1.0, 'Iris-versicolor'],\n",
       "       [6.2, 2.2, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [5.6, 2.5, 3.9, 1.1, 'Iris-versicolor'],\n",
       "       [5.9, 3.2, 4.8, 1.8, 'Iris-versicolor'],\n",
       "       [6.1, 2.8, 4.0, 1.3, 'Iris-versicolor'],\n",
       "       [6.3, 2.5, 4.9, 1.5, 'Iris-versicolor'],\n",
       "       [6.1, 2.8, 4.7, 1.2, 'Iris-versicolor'],\n",
       "       [6.4, 2.9, 4.3, 1.3, 'Iris-versicolor'],\n",
       "       [6.6, 3.0, 4.4, 1.4, 'Iris-versicolor'],\n",
       "       [6.8, 2.8, 4.8, 1.4, 'Iris-versicolor'],\n",
       "       [6.7, 3.0, 5.0, 1.7, 'Iris-versicolor'],\n",
       "       [6.0, 2.9, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [5.7, 2.6, 3.5, 1.0, 'Iris-versicolor'],\n",
       "       [5.5, 2.4, 3.8, 1.1, 'Iris-versicolor'],\n",
       "       [5.5, 2.4, 3.7, 1.0, 'Iris-versicolor'],\n",
       "       [5.8, 2.7, 3.9, 1.2, 'Iris-versicolor'],\n",
       "       [6.0, 2.7, 5.1, 1.6, 'Iris-versicolor'],\n",
       "       [5.4, 3.0, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [6.0, 3.4, 4.5, 1.6, 'Iris-versicolor'],\n",
       "       [6.7, 3.1, 4.7, 1.5, 'Iris-versicolor'],\n",
       "       [6.3, 2.3, 4.4, 1.3, 'Iris-versicolor'],\n",
       "       [5.6, 3.0, 4.1, 1.3, 'Iris-versicolor'],\n",
       "       [5.5, 2.5, 4.0, 1.3, 'Iris-versicolor'],\n",
       "       [5.5, 2.6, 4.4, 1.2, 'Iris-versicolor'],\n",
       "       [6.1, 3.0, 4.6, 1.4, 'Iris-versicolor'],\n",
       "       [5.8, 2.6, 4.0, 1.2, 'Iris-versicolor'],\n",
       "       [5.0, 2.3, 3.3, 1.0, 'Iris-versicolor'],\n",
       "       [5.6, 2.7, 4.2, 1.3, 'Iris-versicolor'],\n",
       "       [5.7, 3.0, 4.2, 1.2, 'Iris-versicolor'],\n",
       "       [5.7, 2.9, 4.2, 1.3, 'Iris-versicolor'],\n",
       "       [6.2, 2.9, 4.3, 1.3, 'Iris-versicolor'],\n",
       "       [5.1, 2.5, 3.0, 1.1, 'Iris-versicolor'],\n",
       "       [5.7, 2.8, 4.1, 1.3, 'Iris-versicolor'],\n",
       "       [6.3, 3.3, 6.0, 2.5, 'Iris-virginica'],\n",
       "       [5.8, 2.7, 5.1, 1.9, 'Iris-virginica'],\n",
       "       [7.1, 3.0, 5.9, 2.1, 'Iris-virginica'],\n",
       "       [6.3, 2.9, 5.6, 1.8, 'Iris-virginica'],\n",
       "       [6.5, 3.0, 5.8, 2.2, 'Iris-virginica'],\n",
       "       [7.6, 3.0, 6.6, 2.1, 'Iris-virginica'],\n",
       "       [4.9, 2.5, 4.5, 1.7, 'Iris-virginica'],\n",
       "       [7.3, 2.9, 6.3, 1.8, 'Iris-virginica'],\n",
       "       [6.7, 2.5, 5.8, 1.8, 'Iris-virginica'],\n",
       "       [7.2, 3.6, 6.1, 2.5, 'Iris-virginica'],\n",
       "       [6.5, 3.2, 5.1, 2.0, 'Iris-virginica'],\n",
       "       [6.4, 2.7, 5.3, 1.9, 'Iris-virginica'],\n",
       "       [6.8, 3.0, 5.5, 2.1, 'Iris-virginica'],\n",
       "       [5.7, 2.5, 5.0, 2.0, 'Iris-virginica'],\n",
       "       [5.8, 2.8, 5.1, 2.4, 'Iris-virginica'],\n",
       "       [6.4, 3.2, 5.3, 2.3, 'Iris-virginica'],\n",
       "       [6.5, 3.0, 5.5, 1.8, 'Iris-virginica'],\n",
       "       [7.7, 3.8, 6.7, 2.2, 'Iris-virginica'],\n",
       "       [7.7, 2.6, 6.9, 2.3, 'Iris-virginica'],\n",
       "       [6.0, 2.2, 5.0, 1.5, 'Iris-virginica'],\n",
       "       [6.9, 3.2, 5.7, 2.3, 'Iris-virginica'],\n",
       "       [5.6, 2.8, 4.9, 2.0, 'Iris-virginica'],\n",
       "       [7.7, 2.8, 6.7, 2.0, 'Iris-virginica'],\n",
       "       [6.3, 2.7, 4.9, 1.8, 'Iris-virginica'],\n",
       "       [6.7, 3.3, 5.7, 2.1, 'Iris-virginica'],\n",
       "       [7.2, 3.2, 6.0, 1.8, 'Iris-virginica'],\n",
       "       [6.2, 2.8, 4.8, 1.8, 'Iris-virginica'],\n",
       "       [6.1, 3.0, 4.9, 1.8, 'Iris-virginica'],\n",
       "       [6.4, 2.8, 5.6, 2.1, 'Iris-virginica'],\n",
       "       [7.2, 3.0, 5.8, 1.6, 'Iris-virginica'],\n",
       "       [7.4, 2.8, 6.1, 1.9, 'Iris-virginica'],\n",
       "       [7.9, 3.8, 6.4, 2.0, 'Iris-virginica'],\n",
       "       [6.4, 2.8, 5.6, 2.2, 'Iris-virginica'],\n",
       "       [6.3, 2.8, 5.1, 1.5, 'Iris-virginica'],\n",
       "       [6.1, 2.6, 5.6, 1.4, 'Iris-virginica'],\n",
       "       [7.7, 3.0, 6.1, 2.3, 'Iris-virginica'],\n",
       "       [6.3, 3.4, 5.6, 2.4, 'Iris-virginica'],\n",
       "       [6.4, 3.1, 5.5, 1.8, 'Iris-virginica'],\n",
       "       [6.0, 3.0, 4.8, 1.8, 'Iris-virginica'],\n",
       "       [6.9, 3.1, 5.4, 2.1, 'Iris-virginica'],\n",
       "       [6.7, 3.1, 5.6, 2.4, 'Iris-virginica'],\n",
       "       [6.9, 3.1, 5.1, 2.3, 'Iris-virginica'],\n",
       "       [5.8, 2.7, 5.1, 1.9, 'Iris-virginica'],\n",
       "       [6.8, 3.2, 5.9, 2.3, 'Iris-virginica'],\n",
       "       [6.7, 3.3, 5.7, 2.5, 'Iris-virginica'],\n",
       "       [6.7, 3.0, 5.2, 2.3, 'Iris-virginica'],\n",
       "       [6.3, 2.5, 5.0, 1.9, 'Iris-virginica'],\n",
       "       [6.5, 3.0, 5.2, 2.0, 'Iris-virginica'],\n",
       "       [6.2, 3.4, 5.4, 2.3, 'Iris-virginica'],\n",
       "       [5.9, 3.0, 5.1, 1.8, 'Iris-virginica']], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66116fdf-7ea2-43fb-9452-ac0350a63da9",
   "metadata": {},
   "source": [
    "From this matrix it is clear that our X is contained in the first 4 columns of df, whereas our y is the 5th column. We can slice this numpy matrix as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11205efc-4f6b-4301-8840-93dbb6580280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.values[:, :4].astype(float) # all rows (:), columns 0 -> 3 (:4)\n",
    "y = df.values[:, 4] # all rows (:), 4th column (4)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0b3c8d9-e54e-423f-a61f-32d3d552871a",
   "metadata": {},
   "source": [
    "Indeed, the shapes of the extracted arrays are in accordance with the expectations.\n",
    "\n",
    "Notice how we are changing the type of X to float. This is because the original matrix (df.values) uses a single type, \"object\", for all values. Numpy arrays support single types only (for efficiency reasons) and, since the \"label\" column is a string (object), the \"object\" type is used to represent the entire df.values."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e37d3c4-632f-4010-92a7-d3e9b1be4c3a",
   "metadata": {},
   "source": [
    "We now need to extract a training set (X_train, y_train) and a test set (X_test, y_test). An important property is that there cannot be any point shared between the two (i.e. the two sets cannot overlap). This is because we need to evaluate the performance of our classification model on data that has never seen before by our model (i.e. data that is not in the training set). If this is not the case, the model would have an unfair advantage and we would over-estimate the model's capability to generalize to new data.\n",
    "\n",
    "To guarantee this property, we can use a boolean mask to select only a portion of the dataset. Then, using the negation operator, we can \"flip\" the mask so as to select all remaining values. The following code snippet shows how this works on a toy example."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3ee9670-f13c-4e51-b2f3-cc6b7dbc6b10",
   "metadata": {},
   "source": [
    "We can apply approach of masks to our dataset, by first selecting X_train with a mask and then flipping the mask to select all remaining values (to put in X_test).\n",
    "Our mask will need to contain 150 values: 120 of which (80% of 150) will be true (i.e. will be placed in X_test), whereas the remaining 20% will be set to false (X_test). The 80/20 ratio is a common one for train/test splits. You typically want a larger proportion of data for your training set and a smaller one for the testing (other common splits could be 60/40, 75/25 -- depending on the availability of data)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c744ff97-6b17-45bb-bc36-823adc661949",
   "metadata": {},
   "source": [
    "Clearly, we will not write a mask of 150 values. We can use the \"repetition\" operator (\"\") in python (e.g. `[1] 3 = [1,1,1]). We can repeat the True value 120 times, and the False value 30 times -- then concatenate the two (\"+\" operator) (e.g.[1,2,3] + [4,5,6] = [1,2,3,4,5,6]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d775b8-0b28-43fa-ba99-9fbea7bc707c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_True = [True] * 120 # 80%\n",
    "mask_False = [False] * 30 # 20%\n",
    "mask = np.array(mask_True + mask_False)\n",
    "mask"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48fc2586-fb86-4c42-81fc-e850261d0807",
   "metadata": {},
   "source": [
    "If we use this mask, though, we will select the frist 120 values of X as our training set, and the last 30 values as test. Since, however, our data is ordered by label, we would get all setosa and all versicolor points (+ 20 virginica points) in our training set and 30 for our test set. This is obviously not desirable. Instead, we can shuffle mask so that the selected points will be randomly distributed.\n",
    "\n",
    "np.random.shuffle() shuffles an array in-place. By calling it we can get the shuffled version of mask we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ffbd53-e968-4a2c-8072-dffc4393476f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "       False,  True,  True, False, False,  True,  True,  True, False,\n",
       "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True, False,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True, False,  True, False, False,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True, False,\n",
       "        True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(mask) # ora li mischio tutti\n",
    "mask"
   ]
  },
  {
   "cell_type": "raw",
   "id": "233fddc7-a4be-4522-a05d-aa39031133c3",
   "metadata": {},
   "source": [
    "Now, we can extract our X_train and X_test, as well as y_train and y_test (notice how we can leverage the same mask for both X and y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd5d33b5-c152-46c1-a2b2-b39a62f78437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4), (120,), (30,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[mask] # prendo l'80%\n",
    "X_test = X[~mask] # prendo il restante 20%\n",
    "\n",
    "y_train = y[mask] # prendo l'80%\n",
    "y_test = y[~mask] # prenso il restante 20%\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6cea8ea-99f9-4c7a-89c1-1b4c25f560d9",
   "metadata": {},
   "source": [
    "To make sure that we are approximately retaining the same proportion of labels in the training and test set, we can count how many points of each class we are using for training and for testing. To this end, we can use Counter (which takes an iterable as input and returns a dictionary where keys are elements of the input list and values are the number of occurences for each element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b5e26f-9e85-4d5f-848c-f519336b866e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'Iris-versicolor': 41, 'Iris-virginica': 41, 'Iris-setosa': 38}),\n",
       " Counter({'Iris-setosa': 12, 'Iris-versicolor': 9, 'Iris-virginica': 9}))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e650b5-af52-4168-a780-708086141d38",
   "metadata": {},
   "source": [
    "**es4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46833da0-2afd-4533-b6d5-8998a5e49c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors1:\n",
    "    def __init__(self, k, distance_metric=\"euclidean\"):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Store the 'prior knowledge ' of you model that will be used to predict new labels .\n",
    "        : param X : input data points , ndarray , shape = (R,C).\n",
    "        : param y : input labels , ndarray , shape = (R ,).\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Run the KNN classification on X.\n",
    "        : param X: input data points , ndarray , shape = (N,C).\n",
    "        : return : labels : ndarray , shape = (N ,).\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "670e7501-bf15-4bf8-a0f5-0dc0974f9699",
   "metadata": {},
   "source": [
    "For the KNN algorithm, the \"fit\" part is particularly straightforward: since all KNN does is computing the distance between training points and test points, the \"fit\" step will only need to store the training set for later use.\n",
    "\n",
    "Notice how the syntax used for this class (which is also the syntax used for all sklearn models) does not distinguish between train and test arrays (i.e. it always uses X and y). The context in which does arrays are used should be enough to understand whether we are referring to a training or a test set. For this solution, though, we will disambiguate between training and test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c86d89-36fc-4c71-ad94-811b8b2bcc8e",
   "metadata": {},
   "source": [
    "**es5**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25b7441a-2d32-46c5-8212-042e57b6bcdd",
   "metadata": {},
   "source": [
    "We now need to implement three different distances: euclidean, cosine and Manhattan. We will then need to compute these distances between all points in the training set and all points in the test set. Since distances are scalar values, the output should be a distance matrix of M rows and N columns, where M is the number of points in our training set, and N is the number of points in our test set (for the Iris case, therefore, this will be a 120x30 matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a634ea9-0afc-4e0a-a810-c7bd48a96c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EUCLIDEAN DISTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e66230-d0dd-4d5f-8257-627d84c8fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_non_numpy(p, q):\n",
    "    cumul = 0\n",
    "    for i in range(len(p)):\n",
    "        cumul += (p[i] - q[i])**2\n",
    "    return cumul ** 0.5\n",
    "    \n",
    "def euclidean_numpy(p, q): # tratto com\n",
    "    return ((p-q)**2).sum()**.5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae98131d-3182-400a-8002-e6c822edba2b",
   "metadata": {},
   "source": [
    "First, we need to compute the difference between all X_train points and X_test points. X_train - X_test is not as valid solution, from both a shape-wise and a logical perspective. Instead we need, for each of the M points in X_train, to compute N subtractions (one for each of the N points in X_test).\n",
    "\n",
    "Ideally, therefore, our broadcasted training set should have shape (M, N, n) (we replicate each of the M points N times). Since we can leverage broadcasting, we can have a training set with shape (M, 1, n) be broadcasted when subtracting the (N, n) matrix from it (indeed, those two shape are compatible and broadcasted to shape (M, N, n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d4e68d-4d39-428a-84d4-5a473b1b5180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped = np.expand_dims(X_train, 1) # np.expand_dims(array, axis) aggiunge una nuova dimensione allâ€™array lungo lâ€™asse specificato.\n",
    "X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5806aedd-3777-49d8-86a0-66abfb238790",
   "metadata": {},
   "source": [
    "From this, we can subtract X_test and obtain the (M, N, n) matrix we are loo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb3473f1-d2b0-4596-a7fb-cf2f76b96d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_diff = X_train_reshaped - X_test\n",
    "X_diff.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2e94232-00be-4e71-b0f4-f513db2033f6",
   "metadata": {},
   "source": [
    "On the third dimension we have the difference across all dimensions. We can square those values (to obtain the squared distance) and sum them (along the correct axis). Then, we can take the (element-wise) square root of the matrix: this will be our distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a8ecc6e-d9cf-48ec-ac17-d9d9289bf104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix = ((X_diff**2).sum(axis=2))**.5\n",
    "# Sommi i quadrati lungo lâ€™asse 2 (cioÃ¨ lungo le feature), ottenendo la somma dei quadrati delle differenze per ciascuna coppia di punti.\n",
    "# facciuo la radice per ottenere la distanza euclidea\n",
    "dist_matrix.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89c4c151-0147-4cae-af13-be3b538e3ed9",
   "metadata": {},
   "source": [
    "To make sure that the values are indeed distances, we can take the i-th X_train element and j-th X_test element and make sure that their distance (as computed by euclidean_numpy) is the same as the (i,j) position in dist_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09a8b754-9d37-47fa-822f-ac095464f386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(3.0033314835362415), np.float64(3.0033314835362415))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 25\n",
    "j = 14\n",
    "dist_matrix[i,j], euclidean_numpy(X_train[i], X_test[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e1fff9b-579c-46e7-9307-b0bfed59736f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50990195, 0.17320508, 0.46904158, ..., 4.84045452, 4.88057374,\n",
       "        5.01996016],\n",
       "       [0.3       , 0.42426407, 0.17320508, ..., 4.85180379, 4.89182992,\n",
       "        5.07247474],\n",
       "       [0.24494897, 0.5       , 0.31622777, ..., 4.87339717, 4.9132474 ,\n",
       "        5.10489961],\n",
       "       ...,\n",
       "       [4.66154481, 4.39772669, 4.45757782, ..., 0.46904158, 0.5       ,\n",
       "        0.60827625],\n",
       "       [4.84871117, 4.58911756, 4.67225855, ..., 0.69282032, 0.67082039,\n",
       "        0.6244998 ],\n",
       "       [4.29883705, 4.0607881 , 4.10609303, ..., 0.79372539, 0.83666003,\n",
       "        1.12249722]], shape=(120, 30))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def euclidean(X_train, X_test):\n",
    "    X_train_reshaped = np.expand_dims(X_train, 1)\n",
    "    X_diff = X_train_reshaped - X_test\n",
    "    dist_matrix = ((X_diff**2).sum(axis=2))**.5\n",
    "    return dist_matrix\n",
    "\n",
    "euclidean(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9c3ec83-0975-49b1-870d-9cf40e074856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE DISTANCE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6a9ccbc-25e4-410d-8b5d-c1f1ec060786",
   "metadata": {},
   "source": [
    "For the cosine distance, the situation is significantly easier. Given a vector p and a vector q, we know that the dot product between the two corresponds to  ||p||2||q||2cosÎ¸, where Î¸ is the angle between the two vector, whose absolute value is referred to as the cosine similarity. The cosine distance is 1 - cosine similarity."
   ]
  },
  {
   "cell_type": "raw",
   "id": "92b36bf8-6eed-4fb8-8250-d3b1c0e437e6",
   "metadata": {},
   "source": [
    "We can build the dot product of each vector of X_train with each vector of X_test by computing the matrix multiplication of the two (with X_test transposed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "927edf4c-9e1a-4fac-947a-c0e494acf99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_prods = X_train @ X_test.T # the @ operator is a short-hand for the matrix multiplication function\n",
    "dot_prods.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad74de58-cc18-41af-ba3b-57df5047f1f1",
   "metadata": {},
   "source": [
    "We know that we need to normalize the previous result by the norms of the vectors. We can leverage broadcasting to this end (by first dividing by a column vector with all norms of X_train points, then dividing by a row vector with the norms of X_test points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d7e36be-6313-41ec-bbd9-89ef40c46192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = ((X_train**2).sum(axis=1)**.5).reshape(-1,1) # Calcola la norma euclidea di ogni riga e la rende vettore colonna\n",
    "X_test_norm = ((X_test**2).sum(axis=1)**.5).T # Calcola le norme dei vettori di test, ma .T non cambia nulla se Ã¨ 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f98b031c-fe0c-48a5-9810-0af5b2f8104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = 1 - abs(dot_prods / X_train_norm.reshape(-1,1) / X_test_norm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c637d407-d6fb-46b7-bbcd-ff7036f98316",
   "metadata": {},
   "source": [
    "Note that, when computing X_train_norm, we need to reshape it into a column vector (reshape(-1,1)). This is needed because the sum() collapses a dimension, thus making the result 1-dimensional (i.e. a row vector). By reshaping it, we convert the row into a column.\n",
    "\n",
    "We can put together the previous pieces and build a cosine function that that computes the desired matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45047427-d26a-4cd7-ab79-38008321f58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.26527175e-05, 2.20406477e-04, 1.23549111e-03, ...,\n",
       "        1.31113782e-01, 1.32972452e-01, 1.21744289e-01],\n",
       "       [1.20854727e-03, 1.08610426e-03, 3.47906668e-04, ...,\n",
       "        1.17493455e-01, 1.19361881e-01, 1.09220997e-01],\n",
       "       [7.83016618e-04, 2.30526711e-04, 6.14085381e-04, ...,\n",
       "        1.12264688e-01, 1.14135699e-01, 1.04040386e-01],\n",
       "       ...,\n",
       "       [1.06371327e-01, 9.97798295e-02, 9.54683371e-02, ...,\n",
       "        1.22522611e-03, 1.36337068e-03, 6.88414167e-04],\n",
       "       [1.14330965e-01, 1.07526136e-01, 1.05294328e-01, ...,\n",
       "        2.83964929e-03, 2.65039699e-03, 1.38667577e-03],\n",
       "       [1.11540581e-01, 1.04482513e-01, 1.00773155e-01, ...,\n",
       "        1.33079650e-03, 1.57590237e-03, 1.28808123e-03]], shape=(120, 30))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosine(X_train, X_test):\n",
    "    X_train_norm = ((X_train**2).sum(axis=1)**.5).reshape(-1,1)\n",
    "    X_test_norm = ((X_test**2).sum(axis=1)**.5)\n",
    "    dot_prods = X_train @ X_test.T \n",
    "    dist_matrix = 1 - abs(dot_prods / X_train_norm.reshape(-1,1) / X_test_norm)\n",
    "    return dist_matrix\n",
    "\n",
    "cosine(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e72faefc-f670-4163-8aca-729d86974d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANHATTAN DISTANCE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "822f6d51-96b7-4c8b-a539-7f66fa7bab5b",
   "metadata": {},
   "source": [
    "Based on the solution for the euclidean distance, we can easily work out a function that computes the Manhattan distance. Instead of squaring the values and taking the square root, we can compute the absolute value of the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35bb5947-38c1-420d-8cfd-4c9fe5184b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.3, 0.8, ..., 8.1, 8.2, 8.4],\n",
       "       [0.5, 0.6, 0.3, ..., 7.8, 7.9, 8.3],\n",
       "       [0.4, 0.7, 0.4, ..., 8.1, 8.2, 8.4],\n",
       "       ...,\n",
       "       [7.7, 7.4, 7.3, ..., 0.8, 0.9, 1.1],\n",
       "       [7.9, 7.2, 7.7, ..., 1.2, 1.1, 1.1],\n",
       "       [6.8, 6.5, 6.4, ..., 1.5, 1.6, 2. ]], shape=(120, 30))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def manhattan(X_train, X_test):\n",
    "    X_train_reshaped = np.expand_dims(X_train, 1)\n",
    "    X_diff = X_train_reshaped - X_test\n",
    "    dist_matrix = abs(X_diff).sum(axis=2) # come la euclidea ma faccio la differenza in valore assoluto \n",
    "    return dist_matrix\n",
    "\n",
    "manhattan(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a889ec96-e951-4bf1-bf6f-e6631be24c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors2:\n",
    "    def __init__(self, k, distance_metric=\"euclidean\"):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        self.X_train_reshaped = np.expand_dims(self.X_train, 1)\n",
    "        self.X_train_norm = ((self.X_train**2).sum(axis=1)**.5).reshape(-1,1)\n",
    "\n",
    "    def _euclidean(self, X_test):\n",
    "        X_diff = self.X_train_reshaped - X_test\n",
    "        dist_matrix = ((X_diff**2).sum(axis=2))**.5\n",
    "        return dist_matrix\n",
    "\n",
    "    def _cosine(self, X_test):\n",
    "        X_test_norm = ((X_test**2).sum(axis=1)**.5)\n",
    "        dot_prods = X_train @ X_test.T \n",
    "        dist_matrix = 1 - abs(dot_prods / self.X_train_norm.reshape(-1,1) / X_test_norm)\n",
    "        return dist_matrix\n",
    "\n",
    "    def _manhattan(self, X_test):\n",
    "        X_diff = self.X_train_reshaped - X_test\n",
    "        dist_matrix = abs(X_diff).sum(axis=2)\n",
    "        return dist_matrix\n",
    "\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72c1f3e5-6af0-426c-977a-add057c9a3cc",
   "metadata": {},
   "source": [
    "Notice that there are some arrays (X_train_norm and X_train_reshaped) that can be worked out from X_train alone. We can move those operations into the fit() function: in this way, they will only be computed once (at training time) and can be used for multiple predictions, with no need to recompute them every time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ea372-2e08-47d8-b236-3d8f8479e220",
   "metadata": {},
   "source": [
    "**es6**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "638ab391-709d-429a-9d8c-afd063f358a9",
   "metadata": {},
   "source": [
    "We now need to make a prediction for each point in X_test. Before we do this, we need to pass from an MxN matrix (i.e. the distance matrix computed before) to an NxK matrix (i.e. a matrix with the indices of the K nearest neighbors for each point in X_test).\n",
    "\n",
    "To this end, we can use argsort, which returns the indices of the input data in sorted order. In other words, given an unsorted array, argsort returns an index that can be used to access the target array and obtain a sorted version of it. \n",
    "\n",
    "If we select the first K values of argsort (applied on the j-th column of the distance matrix), we will get the indices of the K closest training points to the j-th test point.\n",
    "\n",
    "Additionally, argsort allows specifying an axis along which the sorting is done. So, given a distance matrix dist_matrix, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c457035e-fc6a-4f6e-9c2f-df70de8275e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   7,  19],\n",
       "       [ 28,  29,  19],\n",
       "       [ 24,  27,  13],\n",
       "       [ 24,  27,   1],\n",
       "       [  0,   7,  36],\n",
       "       [  0,   7,  36],\n",
       "       [  5,  31,  34],\n",
       "       [  5,   4,  31],\n",
       "       [ 37,  19,  29],\n",
       "       [  6,  13,   2],\n",
       "       [  0,  11,   3],\n",
       "       [ 18,   4,  15],\n",
       "       [ 58,  65,  59],\n",
       "       [ 48,  70,  71],\n",
       "       [ 42,  46,  62],\n",
       "       [ 67,  54,  42],\n",
       "       [ 64,  53,  44],\n",
       "       [ 76,  39,  72],\n",
       "       [ 74,  75,  42],\n",
       "       [ 39,  61,  41],\n",
       "       [ 50,  65,  58],\n",
       "       [ 66,  91, 108],\n",
       "       [ 83,  85,  94],\n",
       "       [109, 100, 117],\n",
       "       [114,  96, 107],\n",
       "       [ 85,  94,  83],\n",
       "       [ 99, 110,  88],\n",
       "       [ 89,  82, 112],\n",
       "       [ 89,  82, 112],\n",
       "       [ 95, 114, 113]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3 # abbiamo deciso di prendere i tre piÃ¹ vicini\n",
    "knn = dist_matrix.argsort(axis=0)[:k, :].T # prendiamo i top k training per tutti i test\n",
    "# ordina indici di train per distanza (una colonna = un test), prendi i primi k e trasponi\n",
    "knn"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9deeb235-7568-4d04-8a23-71b1e9a53526",
   "metadata": {},
   "source": [
    "In this matrix, at row j, we will find the K nearest neighbors of th j-th test point.\n",
    "\n",
    "We can now leverage numpy's indexing to access the actual labels for those nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fbcd322-a7a2-4dd3-9f63-50b0ac380b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-setosa', 'Iris-setosa', 'Iris-setosa'],\n",
       "       ['Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor'],\n",
       "       ['Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor'],\n",
       "       ['Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor'],\n",
       "       ['Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor'],\n",
       "       ['Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor'],\n",
       "       ['Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor'],\n",
       "       ['Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor'],\n",
       "       ['Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor'],\n",
       "       ['Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor'],\n",
       "       ['Iris-versicolor', 'Iris-virginica', 'Iris-virginica'],\n",
       "       ['Iris-virginica', 'Iris-virginica', 'Iris-virginica'],\n",
       "       ['Iris-virginica', 'Iris-virginica', 'Iris-virginica'],\n",
       "       ['Iris-virginica', 'Iris-virginica', 'Iris-virginica'],\n",
       "       ['Iris-virginica', 'Iris-virginica', 'Iris-virginica'],\n",
       "       ['Iris-virginica', 'Iris-virginica', 'Iris-virginica'],\n",
       "       ['Iris-virginica', 'Iris-virginica', 'Iris-virginica'],\n",
       "       ['Iris-virginica', 'Iris-virginica', 'Iris-virginica'],\n",
       "       ['Iris-virginica', 'Iris-virginica', 'Iris-virginica']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[knn] # accediamo al training label associato"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da564c9e-3dcf-4c8d-81ff-047131d0441a",
   "metadata": {},
   "source": [
    "For the 20th test point (index 19), for example, we can see that the K=3 nearest neighbors are labelled as ['Iris-versicolor', 'Iris-virginica', 'Iris-virginica']. With a majority voting, the label assigned to the first test point will therefore be Iris-virginica. We can check y_test[19] to see if we got it right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75d3fd9e-bb7b-4603-a82b-d7c20a5fb75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-versicolor'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[19]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "776583be-e9ec-4805-8284-15eb1b900266",
   "metadata": {},
   "source": [
    "Now, for each row in the knn matrix, we should do a majority voting to assign a label. A simple solution to this problem is counting the number of times each label appears in each row. For this task, the Counter class comes to mind. We can iterate over each row of knn and apply Counter to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "243da734-671e-4910-bdaa-48b04218b3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-setosa': 3}),\n",
       " Counter({'Iris-versicolor': 3}),\n",
       " Counter({'Iris-versicolor': 3}),\n",
       " Counter({'Iris-versicolor': 3}),\n",
       " Counter({'Iris-versicolor': 3}),\n",
       " Counter({'Iris-versicolor': 3}),\n",
       " Counter({'Iris-versicolor': 3}),\n",
       " Counter({'Iris-versicolor': 3}),\n",
       " Counter({'Iris-versicolor': 3}),\n",
       " Counter({'Iris-versicolor': 3}),\n",
       " Counter({'Iris-virginica': 2, 'Iris-versicolor': 1}),\n",
       " Counter({'Iris-virginica': 3}),\n",
       " Counter({'Iris-virginica': 3}),\n",
       " Counter({'Iris-virginica': 3}),\n",
       " Counter({'Iris-virginica': 3}),\n",
       " Counter({'Iris-virginica': 3}),\n",
       " Counter({'Iris-virginica': 3}),\n",
       " Counter({'Iris-virginica': 3}),\n",
       " Counter({'Iris-virginica': 3})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(Counter, y_train[knn]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45540fc4-bbd4-4f78-9329-dfaf3a1a5e20",
   "metadata": {},
   "source": [
    "This shows the votes cast for each label. We can also build a function that directly returns the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00dc7508-5322-4dbd-a17c-2288c0689b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica'], dtype='<U15')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def majority_voting(votes): # per assegnare la classe devo prendere il top voto\n",
    "    count = Counter(votes)\n",
    "    return count.most_common(1)[0][0] # most_common(n) returns a list with the n most recurring votes (n=1 -> top vote)\n",
    "    # we only need the first one [0][0]\n",
    "\n",
    "np.array(list(map(majority_voting, y_train[knn])))\n",
    "#np.array([majority_voting(y_train[knn][i]) for i in range(len(y_train[knn])) ])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34337b4e-4018-4647-a150-3dd907503f4d",
   "metadata": {},
   "source": [
    "We can now condense all previous steps into our predict() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58aeeed0-52cc-43c4-ac12-0d57c9e9861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _majority_voting(votes):\n",
    "    count = Counter(votes)\n",
    "    return count.most_common(1)[0][0] # most_common(n) returns a list with the n most recurring votes (n=1 -> top vote)\n",
    "\n",
    "class KNearestNeighbors3:\n",
    "    def __init__(self, k, distance_metric=\"euclidean\"):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        self.X_train_reshaped = np.expand_dims(self.X_train, 1)\n",
    "        self.X_train_norm = ((self.X_train**2).sum(axis=1)**.5).reshape(-1,1)\n",
    "\n",
    "    def _euclidean(self, X_test):\n",
    "        X_diff = self.X_train_reshaped - X_test\n",
    "        dist_matrix = ((X_diff**2).sum(axis=2))**.5\n",
    "        return dist_matrix\n",
    "\n",
    "    def _cosine(self, X_test):\n",
    "        X_test_norm = ((X_test**2).sum(axis=1)**.5).T\n",
    "        dot_prods = X_train @ X_test.T \n",
    "        dist_matrix = 1 - abs(dot_prods / self.X_train_norm.reshape(-1,1) / X_test_norm)\n",
    "        return dist_matrix\n",
    "\n",
    "    def _manhattan(self, X_test):\n",
    "        X_diff = self.X_train_reshaped - X_test\n",
    "        dist_matrix = abs(X_diff).sum(axis=2)\n",
    "        return dist_matrix\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        if self.distance_metric == \"euclidean\":\n",
    "            dist_matrix = self._euclidean(X_test)\n",
    "        elif self.distance_metric == \"cosine\":\n",
    "            dist_matrix = self._cosine(X_test)\n",
    "        elif self.distance_metric == \"manhattan\":\n",
    "            dist_matrix = self._manhattan(X_test)\n",
    "        else:\n",
    "            raise Exception(\"Unknown distance metric\")\n",
    "        knn = dist_matrix.argsort(axis=0)[:self.k, :].T\n",
    "        y_pred = np.array([ majority_voting(self.y_train[knn][i]) for i in range(len(self.y_train[knn]))])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a392cbe5-eb38-4be1-add5-eda189728be9",
   "metadata": {},
   "source": [
    "We can now instantiate our classifier, \"train\" it and get a prediction out of it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "157a88b3-cda7-4f29-888e-792ce6f9a690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica'], dtype='<U15')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNearestNeighbors3(3, \"cosine\")\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da154f5-820d-4625-a98b-8d73a95b1837",
   "metadata": {},
   "source": [
    "**es7**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a4bb4da-74b8-4223-99e0-65a8f93eab37",
   "metadata": {},
   "source": [
    "We can now proceed with computing our model's accuracy. We can build an accuracy_score() function that returns the fraction of correctly predicted occurences as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25f4c6da-3231-4edf-ab93-7be684aeb222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    return (y_true==y_pred).sum()/len(y_true) # conto quanti ne ho predetti correttamwente "
   ]
  },
  {
   "cell_type": "raw",
   "id": "298c5312-b7c3-40fd-bdea-8f4b9a975d95",
   "metadata": {},
   "source": [
    "This function leverages the fact that booleans (the output of the equality check) are stored as 0's and 1's in numpy (therefore, using sum() on a boolean array returns the number of True values).\n",
    "\n",
    "Let's now measure the accuracy of our model, comparing y_test and y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c773fdc2-6419-45b8-999e-57fb07e9a7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1a4c717-e79f-4293-8731-5265157715c7",
   "metadata": {},
   "source": [
    "Our model has exceedingly good performance (100% of correct guesses!). This is typically not the case for real-world problems. For this specific case, two factors caused this outstanding performance:\n",
    "\n",
    "1. Trivial task (the Iris dataset is a so-called toy dataset, given how simple it is to approach)\n",
    "2. Small dataset (our test set is comprised of 30 samples -- it is not particularly hard to predict 30 samples right, specifically with a simple problem such as this one!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb256f-4a7f-4e95-8a20-480d53d5b9d2",
   "metadata": {},
   "source": [
    "**es8**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72a81049-0a30-439a-a331-7a9cc316dd19",
   "metadata": {},
   "source": [
    "This task requires slightly changing the way our predict() function works. Instead of weighting each vote with a standard weight of \"1\" (as previously done), we should now weight each vote with the inverse of the distance between the training and the test points.\n",
    "\n",
    "Luckily, our code is well-structured, and this change only slightly impacts the previously written code.\n",
    "\n",
    "The _majority_voting() function should no longer only count frequencies, but rather sum weights. We will therefore add an additional parameter to it, w (representing the weight of each of the votes in votes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c687ebaf-d721-44c8-940d-daa9381cdc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict # inizializza dizionari con valori di default a zero\n",
    "\n",
    "def _weighted_majority_voting(votes, weights):\n",
    "    # we now compute `count` as a sum of weights\n",
    "    # (no longer through Counter -- which effectively\n",
    "    # weighted all votes as \"1\")\n",
    "    count = defaultdict(lambda: 0)\n",
    "    for vote, weight in zip(votes, weights):\n",
    "        count[vote] += weight\n",
    "    return max(count.items(), key=lambda x: x[1])[0] # return the max value (use a custom key extractor)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "738e3e02-f6b6-4f02-9fe6-914b222a0208",
   "metadata": {},
   "source": [
    "Next, we need to modify predict() to pass the weights along with the labels. We can do this by using the already available knn matrix. Indeed, by using take_along_axis, we can extract the distances corresponding to the neighbors in knn. By taking the inverse of those values, we should the weights needed.\n",
    "\n",
    "But, if we stop for a moment, we might realize something unexpected would happen if we simply take the inverse the distances. Indeed, if we had a point with distance 0 from our target point (i.e., we know a point in our training set that is identical to the one we want to predict), we would get a 0 denominator, with the problems that come with it.\n",
    "\n",
    "So, instead, we can add a small delta (e.g. 10^-5) to the distances before inverting them. This, along the fact that distances are non-negative, guarantees that we will never have divisions by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c311a937-9bc8-4c56-8538-4af463df254a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = 1/(np.take_along_axis(dist_matrix, knn.T, 0)+1e-5)\n",
    "[ _weighted_majority_voting(y_train[knn][i], weights[:, i]) for i in range(len(y_train[knn])) ]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8e9ba9f-4ecb-4cc0-bd40-f52f0c4f3b53",
   "metadata": {},
   "source": [
    "Notice that the delta we are adding to each distance should not significantly alter the value. We can verify the average value of distances with the following approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91965dc9-5bbc-41a0-bafc-d073b07f3192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0009395660236605208)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take_along_axis(dist_matrix, knn.T, 0).max()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08bb40f2-88af-4619-87fc-fd3456d2fecb",
   "metadata": {},
   "source": [
    "So, taking a value that is 2 orders of magnitude lower than the largest distance should not affect the results significantly (clearly, though, it does affect how much we are weighting the case for distance zero).\n",
    "\n",
    "We can now put together everything we have come up with and build a new version of KNN (this time with an extra parameter, weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2efbcb0d-1062-4d95-8758-4c9924e59b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def _weighted_majority_voting(votes, weights):\n",
    "    # we now compute `count` as a sum of weights\n",
    "    # (no longer through Counter -- which effectively\n",
    "    # weighted all votes as \"1\")\n",
    "    count = defaultdict(lambda: 0)\n",
    "    for vote, weight in zip(votes, weights):\n",
    "        count[vote] += weight\n",
    "    return max(count.items(), key=lambda x: x[1])[0] # return the max value (use a custom key extractor)\n",
    "\n",
    "\n",
    "def _majority_voting(votes):\n",
    "    count = Counter(votes)\n",
    "    return count.most_common(1)[0][0] # most_common(n) returns a list with the n most recurring votes (n=1 -> top vote)\n",
    "\n",
    "class KNearestNeighbors4:\n",
    "    def __init__(self, k, distance_metric=\"euclidean\", weights=\"uniform\"):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.weights = weights\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        self.X_train_reshaped = np.expand_dims(self.X_train, 1)\n",
    "        self.X_train_norm = ((self.X_train**2).sum(axis=1)**.5).reshape(-1,1)\n",
    "\n",
    "    def _euclidean(self, X_test):\n",
    "        X_diff = self.X_train_reshaped - X_test\n",
    "        dist_matrix = ((X_diff**2).sum(axis=2))**.5\n",
    "        return dist_matrix\n",
    "\n",
    "    def _cosine(self, X_test):\n",
    "        X_test_norm = ((X_test**2).sum(axis=1)**.5).T\n",
    "        dot_prods = X_train @ X_test.T \n",
    "        dist_matrix = 1 - abs(dot_prods / self.X_train_norm.reshape(-1,1) / X_test_norm)\n",
    "        return dist_matrix\n",
    "\n",
    "    def _manhattan(self, X_test):\n",
    "        X_diff = self.X_train_reshaped - X_test\n",
    "        dist_matrix = abs(X_diff).sum(axis=2)\n",
    "        return dist_matrix\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        if self.distance_metric == \"euclidean\":\n",
    "            dist_matrix = self._euclidean(X_test)\n",
    "        elif self.distance_metric == \"cosine\":\n",
    "            dist_matrix = self._cosine(X_test)\n",
    "        elif self.distance_metric == \"manhattan\":\n",
    "            dist_matrix = self._manhattan(X_test)\n",
    "        else:\n",
    "            raise Exception(\"Unknown distance metric\")\n",
    "        \n",
    "        knn = dist_matrix.argsort(axis=0)[:self.k, :].T\n",
    "        if self.weights == \"uniform\":\n",
    "            y_pred = np.array([ majority_voting(self.y_train[knn][i]) for i in range(len(self.y_train[knn])) ])\n",
    "        elif self.weights == \"distance\":\n",
    "            weights = 1/(np.take_along_axis(dist_matrix, knn.T, 0)+1e-5)\n",
    "            y_pred = np.array([ _weighted_majority_voting(y_train[knn][i], weights[:, i]) for i in range(len(y_train[knn])) ])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fa2a01d-84ef-451b-8ee6-e36dd4fbf6e1",
   "metadata": {},
   "source": [
    "Let's make sure everything is still working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d3e88a0-dcfe-4709-80a4-95b8dda164db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNearestNeighbors4(5, \"manhattan\", \"uniform\")\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e422e20-7613-4352-a443-a9f4ae828169",
   "metadata": {},
   "source": [
    "We can verify whether KNN is correctly weighting samples with one simple trick. If we use a value of k greater than (or close to) the number of samples in the training set, we can expect the following two behaviors:\n",
    "\n",
    "- from weights=uniform, we should always get the label of the class that has a majority of labels (because we are selecting all labels, hence the winning class will always be the most populous one\n",
    "- from weights=distance, on the other hand, we should be able to limit the \"damage\" done by this unacceptable value of k, since further away points will be weighted less than closer ones.\n",
    "\n",
    "Based on the expected result for uniform, we can make a prediction of the accuracy on the test set. This will be the fraction of values in y_test that belong to most populous class in y_train (since KNN should always predict the most common class, and will only get right (and get points when computing the accuracy) those entries that indeed belong to the most common training class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "928ae35d-7c44-4e0c-abf9-27f270628e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test).count(Counter(y_train).most_common(1)[0][0]) / len(y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7bd6f3ca-34e1-4551-8d44-af868969e00e",
   "metadata": {},
   "source": [
    "In the code above, we first compute the most common value of y_train (using Counter's most_common() function we have already seen -- Counter(y_train).most_common(1)[0][0]. Then, we compute the number of elements in y_test with that sepcific value (using list's count() function), then compute the fraction of elements in y_test with that value (by dividing by len(y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b857d014-f889-4de9-8415-c5feb8681271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNearestNeighbors(120, \"euclidean\", \"uniform\")\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e90e139a-f40d-498c-b5d8-4c33e3809e99",
   "metadata": {},
   "source": [
    "As expected. As for the distance scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe6b2faa-7f7c-4792-8952-6dfef15f03d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNearestNeighbors(120, \"euclidean\", \"distance\")\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f7fd52e-6626-4ed0-9a8e-e239243c9491",
   "metadata": {},
   "source": [
    "A much better result. This tells us that, in a way, using this weighting scheme makes up for a poorly selected (too high) value of K. Note that, in this trivial case, we are getting perfect results even with an absurdly large value of K. In more reasonable scenarios (i.e. not for toy datasets), you will get better results than using a uniform scheme, but probably not as good as when using a reasonable value of K."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc5e9e-a54d-4741-93e9-e06bc3110759",
   "metadata": {},
   "source": [
    "**es9**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50bb1de8-f36a-4582-985e-26db80ca12bb",
   "metadata": {},
   "source": [
    "We can now proceed to loading the MNIST dataset, extract 80% of the data for training and 20% for testing, and see how well KNN fares on a slightly harder problem.\n",
    "\n",
    "The code required for this exercise is pretty much the same we used throughout the code except for the fact that we now need to sample 100 points per digit. We can do this sampling creating a mask for each of the 10 digits (y==Digit) and selecting the first 100 values for each of them (as for y, given that we are selecting 100 '0's, 100 '1's, 100 '2's etc., we can simply create an array with 100 '0's, 100 '1's, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc5c9525-a41e-4732-98fb-11774596fbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 784), (200, 784), (800,), (200,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"mnist_test.csv\", header=None)\n",
    "X = df.values[:, 1:].astype(float) # all cols but the first one (784 cols in this case)\n",
    "y = df.values[:, 0] # first column, with the label info\n",
    "\n",
    "# here, we use vstack and hstack to stack (vertical and horizontally, respectively)\n",
    "# different arrays/lists.\n",
    "X_100 = np.vstack([ X[y==d][:100] for d in range(10) ])\n",
    "y_100 = np.hstack([ [d]*100 for d in range(10) ])\n",
    "\n",
    "# generalized version of the previous code (generates 80/20 split)\n",
    "mask = np.array([True] * int(len(X_100)*.8) + [False] * (len(X_100)-int(len(X_100)*.8)))\n",
    "np.random.shuffle(mask)\n",
    "\n",
    "X_train = X_100[mask]\n",
    "X_test = X_100[~mask]\n",
    "\n",
    "y_train = y_100[mask]\n",
    "y_test = y_100[~mask]\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd4d542d-5f0b-48c4-98c5-a801711f9fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.82)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNearestNeighbors4(5, \"euclidean\", \"uniform\")\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4061ccd6-a5f1-4653-9501-7c7b6f6fd871",
   "metadata": {},
   "source": [
    "All is well. Notice that we are undersampling our dataset to obtain more reasonable training times. For larger problems, KNN will take (much) longer. It is not a particularly efficient algorithm, since it does not build any meaningful structure that allows for faster computations.\n",
    "\n",
    "We can run a few more tests (e.g. the \"distance\" vs \"uniform\" test with a large K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13a86d81-55e4-43f9-b752-c748258af78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform 0.065\n",
      "distance 0.41\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNearestNeighbors4(800, \"euclidean\", \"uniform\")\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "print(\"uniform\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "knn_model = KNearestNeighbors4(800, \"euclidean\", \"distance\")\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "print(\"distance\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b43f0176-3bb2-498b-a9e6-f83ba85f88ef",
   "metadata": {},
   "source": [
    "As previously mentioned, this unreasonable value for K leads to more reasonable results when wheighting each vote (though, in this case, we have a significant degradation in performance, compared to the case where K has a more reasonable value)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4f9db-2613-4d07-b22f-259d54c45453",
   "metadata": {},
   "source": [
    "**es10**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "197d9600-63bd-4ea9-a01d-241d3ded17ed",
   "metadata": {},
   "source": [
    "Let's now try to find some meaningful configurations of parameters for our KNN classifier.\n",
    "\n",
    "Since the Iris dataset is so simple, it will well with pretty much any configuration. We will instead focus on MNIST, which poses a slightly more difficult challenge.\n",
    "\n",
    "When searching for a specific configuration of parameters, you may end up running a \"grid search\". This means trying out different combinations of parameters selected from lists of possible values (e.g. if K can be either of [2, 10, 50] and weight one of [\"uniform\", \"distance\"], you will try all possible combinations: [2, \"uniform\"], [2, \"distance\"], [10, \"uniform\"], [10, \"distance\"], [50, \"uniform\"], [50, \"distance\"].\n",
    "\n",
    "The number of configurations does not scale well with the number of parameters being tuned, nor does it scale well with the number of possible values each parameter can have, but this may often be a reasonable approach (if the parameters to be tuned and their values are chosen wisely).\n",
    "\n",
    "You will run such grid searches in future labs. For the time being, we will analyze how KNN performs as we vary value of K. More specifically, let's try running KNN with values from 3 to 103, with step 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "811dd63a-8e40-4da8-8e5e-e658bb24e92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.835\n",
      "13 0.815\n",
      "23 0.78\n",
      "33 0.73\n",
      "43 0.695\n",
      "53 0.695\n",
      "63 0.685\n",
      "73 0.665\n",
      "83 0.67\n",
      "93 0.645\n",
      "103 0.64\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "k_values = list(range(3, 104, 10))\n",
    "for k in k_values:\n",
    "    knn_model = KNearestNeighbors4(k, \"euclidean\", \"distance\")\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(k, accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f2fe714-fb1f-4285-b785-bce0af73e25c",
   "metadata": {},
   "source": [
    "We can already see that large values of K are not particularly suitable. Let's plot this result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c2623a2-892b-4ee3-829f-12eba17e43da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(k_values, accuracies)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34256b23-7f06-448f-ab5f-d5b8a0723546",
   "metadata": {},
   "source": [
    "This lets us know that low values of K should be preferrable, for this problem. So let's now try a narrower range of values, for example 2 to 10, with a step of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7aec570f-edf8-41d9-9043-895e2d398319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.815\n",
      "3 0.835\n",
      "4 0.835\n",
      "5 0.825\n",
      "6 0.82\n",
      "7 0.815\n",
      "8 0.815\n",
      "9 0.805\n",
      "10 0.805\n",
      "11 0.81\n",
      "12 0.82\n",
      "13 0.815\n",
      "14 0.805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = []\n",
    "k_values = list(range(2, 15))\n",
    "for k in k_values:\n",
    "    knn_model = KNearestNeighbors(k, \"euclidean\", \"distance\")\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(k, accuracy)\n",
    "\n",
    "plt.plot(k_values, accuracies)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a935737-8d53-4c25-8093-ac08466980a7",
   "metadata": {},
   "source": [
    "We get the best results for small values of K (approx.  2â‰¤Kâ‰¤6). Notice how we reached this result without actually trying all values from 2 to 103, but rather running a \"coarse\" analysis first, identifying promising ranges of values, then running a fine-grained analysis on the range of interest.\n",
    "\n",
    "Finally, notice how the second plot appears to be quite \"bumpy\". We might be tempted to take some decisions based on this (e.g. 4 is a much better value for K than 3, or 5). However, also notice that the y axis range is particularly narrow. There actually isn't much of a difference in the values we have. Indeed, if we plot the results on a more meaningful range of values (e.g. 0.5-1), we get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0da0df5f-f80e-4062-99d9-a377965a5b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1.0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_values, accuracies)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.5,1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f71a6b3-4c11-420a-966b-cdc5b135af01",
   "metadata": {},
   "source": [
    "So, nothing really to worry about.\n",
    "\n",
    "Finally, we can run some simple grid search. We have identified a reasonable range for K, so we can do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e2f125f-e0f9-4960-9b4e-016dd00eefe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815 2 uniform euclidean\n",
      "0.795 2 uniform manhattan\n",
      "0.85 2 uniform cosine\n",
      "0.815 2 distance euclidean\n",
      "0.795 2 distance manhattan\n",
      "0.85 2 distance cosine\n",
      "0.835 3 uniform euclidean\n",
      "0.815 3 uniform manhattan\n",
      "0.865 3 uniform cosine\n",
      "0.835 3 distance euclidean\n",
      "0.815 3 distance manhattan\n",
      "0.865 3 distance cosine\n",
      "0.835 4 uniform euclidean\n",
      "0.835 4 uniform manhattan\n",
      "0.875 4 uniform cosine\n",
      "0.835 4 distance euclidean\n",
      "0.835 4 distance manhattan\n",
      "0.875 4 distance cosine\n",
      "0.82 5 uniform euclidean\n",
      "0.805 5 uniform manhattan\n",
      "0.865 5 uniform cosine\n",
      "0.825 5 distance euclidean\n",
      "0.805 5 distance manhattan\n",
      "0.87 5 distance cosine\n",
      "0.815 6 uniform euclidean\n",
      "0.81 6 uniform manhattan\n",
      "0.88 6 uniform cosine\n",
      "0.82 6 distance euclidean\n",
      "0.81 6 distance manhattan\n",
      "0.88 6 distance cosine\n"
     ]
    }
   ],
   "source": [
    "for k in range(2, 7):\n",
    "    for weights in [\"uniform\", \"distance\"]:\n",
    "        for distance in [ \"euclidean\", \"manhattan\", \"cosine\"]:\n",
    "            knn_model = KNearestNeighbors(k, distance, weights)\n",
    "            knn_model.fit(X_train, y_train)\n",
    "            y_pred = knn_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(accuracy, k, weights, distance)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe2282b9-e6be-4565-b96e-fba803b7cdcc",
   "metadata": {},
   "source": [
    "All models perform fairly well. Notice, however, that for values of k in [4, 5, 6] and for the cosine distance, the model performs slightly better (0.88 - 0.885), regardless of the weighting scheme. This should therefore give us a better idea of reasonable parameters for our model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a40b6850-c06a-4d99-b930-8db9e78e0ce6",
   "metadata": {},
   "source": [
    "Note that, in this case, we are using the test set to draw conclusions on which parameters (called hyperparameters) we should use for our classifier. Therefore, the performance obtained on the test set are not representative of how well our model performs on unseen data (since we are making decisions based on the best results). This set is what we typically refer to as \"validation set\". An additional test set would be needed to assess how well the trained classifier does on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140a1b3-8fcc-485a-9fa1-470e0c39c31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
